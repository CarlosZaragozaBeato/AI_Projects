{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Iris Flower Classification"
      ],
      "metadata": {
        "id": "2o8C3yJdlfLt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "IBS97fAeoEIn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "GQqaqUhsmQvT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "0gmvzM3_p68D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "52waAGvrmRxB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I6KTc_3kqcC_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "3ansAhAHqm83"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "JUaBPDRHq8E5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(IrisClassifier, self).__init__()\n",
        "    self.fc1 = nn.Linear(4, 16)\n",
        "    self.fc2 = nn.Linear(16, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = IrisClassifier()"
      ],
      "metadata": {
        "id": "TsKB4HH8rR54"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "ZEEWisPTsMAf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfsXWWQXsViA",
        "outputId": "6f0d379a-da26-4402-8db1-4c906dc44d1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss: 0.1648169755935669\n",
            "Epoch 1, loss: 0.31817902624607086\n",
            "Epoch 1, loss: 0.4583896994590759\n",
            "Epoch 1, loss: 0.6056092232465744\n",
            "Epoch 1, loss: 0.7491379827260971\n",
            "Epoch 1, loss: 0.8848067671060562\n",
            "Epoch 1, loss: 1.0207010358572006\n",
            "Epoch 1, loss: 1.1510581523180008\n",
            "Epoch 2, loss: 0.12807951867580414\n",
            "Epoch 2, loss: 0.25663962960243225\n",
            "Epoch 2, loss: 0.37775523215532303\n",
            "Epoch 2, loss: 0.49501923471689224\n",
            "Epoch 2, loss: 0.610022060573101\n",
            "Epoch 2, loss: 0.7241707444190979\n",
            "Epoch 2, loss: 0.8305681943893433\n",
            "Epoch 2, loss: 0.9357649981975555\n",
            "Epoch 3, loss: 0.10318322479724884\n",
            "Epoch 3, loss: 0.20683591067790985\n",
            "Epoch 3, loss: 0.2980787381529808\n",
            "Epoch 3, loss: 0.39201752841472626\n",
            "Epoch 3, loss: 0.4949055388569832\n",
            "Epoch 3, loss: 0.579279363155365\n",
            "Epoch 3, loss: 0.6608472168445587\n",
            "Epoch 3, loss: 0.7242841050028801\n",
            "Epoch 4, loss: 0.07330384105443954\n",
            "Epoch 4, loss: 0.15410290658473969\n",
            "Epoch 4, loss: 0.23519383370876312\n",
            "Epoch 4, loss: 0.3050651103258133\n",
            "Epoch 4, loss: 0.3574351780116558\n",
            "Epoch 4, loss: 0.43384360894560814\n",
            "Epoch 4, loss: 0.48232758417725563\n",
            "Epoch 4, loss: 0.5690692998468876\n",
            "Epoch 5, loss: 0.06387997418642044\n",
            "Epoch 5, loss: 0.12918483465909958\n",
            "Epoch 5, loss: 0.17168112099170685\n",
            "Epoch 5, loss: 0.23195424675941467\n",
            "Epoch 5, loss: 0.2849453240633011\n",
            "Epoch 5, loss: 0.3331233896315098\n",
            "Epoch 5, loss: 0.39880144968628883\n",
            "Epoch 5, loss: 0.43814923614263535\n",
            "Epoch 6, loss: 0.06788739562034607\n",
            "Epoch 6, loss: 0.09397671930491924\n",
            "Epoch 6, loss: 0.16151894442737103\n",
            "Epoch 6, loss: 0.19843142293393612\n",
            "Epoch 6, loss: 0.2485275026410818\n",
            "Epoch 6, loss: 0.2756803799420595\n",
            "Epoch 6, loss: 0.33371968008577824\n",
            "Epoch 6, loss: 0.36423439905047417\n",
            "Epoch 7, loss: 0.040046609938144684\n",
            "Epoch 7, loss: 0.07539958134293556\n",
            "Epoch 7, loss: 0.12568875774741173\n",
            "Epoch 7, loss: 0.16805888339877129\n",
            "Epoch 7, loss: 0.2170727662742138\n",
            "Epoch 7, loss: 0.2538888305425644\n",
            "Epoch 7, loss: 0.29295625537633896\n",
            "Epoch 7, loss: 0.31599344685673714\n",
            "Epoch 8, loss: 0.055151574313640594\n",
            "Epoch 8, loss: 0.11193801462650299\n",
            "Epoch 8, loss: 0.13301128149032593\n",
            "Epoch 8, loss: 0.17777777090668678\n",
            "Epoch 8, loss: 0.19917921349406242\n",
            "Epoch 8, loss: 0.23971718177199364\n",
            "Epoch 8, loss: 0.25938088446855545\n",
            "Epoch 8, loss: 0.274880213662982\n",
            "Epoch 9, loss: 0.02676153928041458\n",
            "Epoch 9, loss: 0.058394141495227814\n",
            "Epoch 9, loss: 0.10462546348571777\n",
            "Epoch 9, loss: 0.12662439420819283\n",
            "Epoch 9, loss: 0.14991786144673824\n",
            "Epoch 9, loss: 0.1851735133677721\n",
            "Epoch 9, loss: 0.22949003614485264\n",
            "Epoch 9, loss: 0.25449736416339874\n",
            "Epoch 10, loss: 0.023488381877541542\n",
            "Epoch 10, loss: 0.08177744410932064\n",
            "Epoch 10, loss: 0.11520334146916866\n",
            "Epoch 10, loss: 0.13771996274590492\n",
            "Epoch 10, loss: 0.15958407148718834\n",
            "Epoch 10, loss: 0.18545395880937576\n",
            "Epoch 10, loss: 0.20053887646645308\n",
            "Epoch 10, loss: 0.2324132239446044\n",
            "Epoch 11, loss: 0.020069023594260216\n",
            "Epoch 11, loss: 0.052738653495907784\n",
            "Epoch 11, loss: 0.0710696317255497\n",
            "Epoch 11, loss: 0.08671454340219498\n",
            "Epoch 11, loss: 0.11377205513417721\n",
            "Epoch 11, loss: 0.15295730344951153\n",
            "Epoch 11, loss: 0.16792066674679518\n",
            "Epoch 11, loss: 0.20611452963203192\n",
            "Epoch 12, loss: 0.027542904019355774\n",
            "Epoch 12, loss: 0.04907199554145336\n",
            "Epoch 12, loss: 0.06862487457692623\n",
            "Epoch 12, loss: 0.08520334027707577\n",
            "Epoch 12, loss: 0.10411090031266212\n",
            "Epoch 12, loss: 0.13103049620985985\n",
            "Epoch 12, loss: 0.1583738774061203\n",
            "Epoch 12, loss: 0.17643316090106964\n",
            "Epoch 13, loss: 0.02474846877157688\n",
            "Epoch 13, loss: 0.0588542390614748\n",
            "Epoch 13, loss: 0.06724946107715368\n",
            "Epoch 13, loss: 0.09787215013056993\n",
            "Epoch 13, loss: 0.11149951256811619\n",
            "Epoch 13, loss: 0.12520612310618162\n",
            "Epoch 13, loss: 0.13604454044252634\n",
            "Epoch 13, loss: 0.16006027068942785\n",
            "Epoch 14, loss: 0.01712513342499733\n",
            "Epoch 14, loss: 0.027698727324604988\n",
            "Epoch 14, loss: 0.05298100411891937\n",
            "Epoch 14, loss: 0.06871380470693111\n",
            "Epoch 14, loss: 0.1003302801400423\n",
            "Epoch 14, loss: 0.10664701042696834\n",
            "Epoch 14, loss: 0.13090937910601497\n",
            "Epoch 14, loss: 0.1361190709285438\n",
            "Epoch 15, loss: 0.009836830198764801\n",
            "Epoch 15, loss: 0.02657611109316349\n",
            "Epoch 15, loss: 0.044232483953237534\n",
            "Epoch 15, loss: 0.0529883885756135\n",
            "Epoch 15, loss: 0.0792134078219533\n",
            "Epoch 15, loss: 0.09260762855410576\n",
            "Epoch 15, loss: 0.1122326385229826\n",
            "Epoch 15, loss: 0.12977240607142448\n",
            "Epoch 16, loss: 0.00878115277737379\n",
            "Epoch 16, loss: 0.02991145011037588\n",
            "Epoch 16, loss: 0.049650038592517376\n",
            "Epoch 16, loss: 0.06255269888788462\n",
            "Epoch 16, loss: 0.0762280160561204\n",
            "Epoch 16, loss: 0.0873813210055232\n",
            "Epoch 16, loss: 0.10896670538932085\n",
            "Epoch 16, loss: 0.12273167539387941\n",
            "Epoch 17, loss: 0.019663821905851364\n",
            "Epoch 17, loss: 0.03327472973614931\n",
            "Epoch 17, loss: 0.045534330420196056\n",
            "Epoch 17, loss: 0.05007186904549599\n",
            "Epoch 17, loss: 0.05780688067898154\n",
            "Epoch 17, loss: 0.07671728124842048\n",
            "Epoch 17, loss: 0.09331206185743213\n",
            "Epoch 17, loss: 0.13464885158464313\n",
            "Epoch 18, loss: 0.01215403899550438\n",
            "Epoch 18, loss: 0.021803383715450764\n",
            "Epoch 18, loss: 0.025106988148763776\n",
            "Epoch 18, loss: 0.03674846072681248\n",
            "Epoch 18, loss: 0.04433082160539925\n",
            "Epoch 18, loss: 0.0639854830224067\n",
            "Epoch 18, loss: 0.0864423115272075\n",
            "Epoch 18, loss: 0.10754148033447564\n",
            "Epoch 19, loss: 0.008593741804361343\n",
            "Epoch 19, loss: 0.023691321723163128\n",
            "Epoch 19, loss: 0.028075593523681164\n",
            "Epoch 19, loss: 0.03950495645403862\n",
            "Epoch 19, loss: 0.05188072007149458\n",
            "Epoch 19, loss: 0.06425519473850727\n",
            "Epoch 19, loss: 0.07953829690814018\n",
            "Epoch 19, loss: 0.10418986715376377\n",
            "Epoch 20, loss: 0.011177223175764084\n",
            "Epoch 20, loss: 0.01684107957407832\n",
            "Epoch 20, loss: 0.037370416801422834\n",
            "Epoch 20, loss: 0.04527881974354386\n",
            "Epoch 20, loss: 0.05582632822915912\n",
            "Epoch 20, loss: 0.07405856950208545\n",
            "Epoch 20, loss: 0.08367620641365647\n",
            "Epoch 20, loss: 0.09431483456864953\n",
            "Epoch 21, loss: 0.010012758895754814\n",
            "Epoch 21, loss: 0.015938478522002697\n",
            "Epoch 21, loss: 0.032161044888198376\n",
            "Epoch 21, loss: 0.04700025822967291\n",
            "Epoch 21, loss: 0.053224893752485514\n",
            "Epoch 21, loss: 0.06454489240422845\n",
            "Epoch 21, loss: 0.08047630684450269\n",
            "Epoch 21, loss: 0.0882256985642016\n",
            "Epoch 22, loss: 0.011920932680368423\n",
            "Epoch 22, loss: 0.02634839154779911\n",
            "Epoch 22, loss: 0.0381313432008028\n",
            "Epoch 22, loss: 0.05006521940231323\n",
            "Epoch 22, loss: 0.06655975989997387\n",
            "Epoch 22, loss: 0.07126949541270733\n",
            "Epoch 22, loss: 0.0775432325899601\n",
            "Epoch 22, loss: 0.0844440758228302\n",
            "Epoch 23, loss: 0.003193620592355728\n",
            "Epoch 23, loss: 0.015121350064873695\n",
            "Epoch 23, loss: 0.034417806193232536\n",
            "Epoch 23, loss: 0.038146121660247445\n",
            "Epoch 23, loss: 0.056997413048520684\n",
            "Epoch 23, loss: 0.06974374339915812\n",
            "Epoch 23, loss: 0.07419580523855984\n",
            "Epoch 23, loss: 0.07766463025473058\n",
            "Epoch 24, loss: 0.014470430091023445\n",
            "Epoch 24, loss: 0.019543193746358156\n",
            "Epoch 24, loss: 0.036792362574487925\n",
            "Epoch 24, loss: 0.04626615112647414\n",
            "Epoch 24, loss: 0.05360245192423463\n",
            "Epoch 24, loss: 0.05815656762570143\n",
            "Epoch 24, loss: 0.06500749615952373\n",
            "Epoch 24, loss: 0.08261349564418197\n",
            "Epoch 25, loss: 0.004046477843075991\n",
            "Epoch 25, loss: 0.01987250754609704\n",
            "Epoch 25, loss: 0.029761820565909147\n",
            "Epoch 25, loss: 0.038370130117982626\n",
            "Epoch 25, loss: 0.05521463556215167\n",
            "Epoch 25, loss: 0.05780673958361149\n",
            "Epoch 25, loss: 0.0605092307087034\n",
            "Epoch 25, loss: 0.08134934096597135\n",
            "Epoch 26, loss: 0.005971422418951988\n",
            "Epoch 26, loss: 0.009648938197642565\n",
            "Epoch 26, loss: 0.016471076291054487\n",
            "Epoch 26, loss: 0.026061998214572668\n",
            "Epoch 26, loss: 0.03495509037747979\n",
            "Epoch 26, loss: 0.038898668717592955\n",
            "Epoch 26, loss: 0.058551670517772436\n",
            "Epoch 26, loss: 0.08126808097586036\n",
            "Epoch 27, loss: 0.0040696957148611546\n",
            "Epoch 27, loss: 0.00578618177678436\n",
            "Epoch 27, loss: 0.009655895526520908\n",
            "Epoch 27, loss: 0.01538910937961191\n",
            "Epoch 27, loss: 0.026225380948744714\n",
            "Epoch 27, loss: 0.05005245876964182\n",
            "Epoch 27, loss: 0.055783870979212224\n",
            "Epoch 27, loss: 0.0818390300264582\n",
            "Epoch 28, loss: 0.021684465929865837\n",
            "Epoch 28, loss: 0.039733605459332466\n",
            "Epoch 28, loss: 0.05243732314556837\n",
            "Epoch 28, loss: 0.0544355905149132\n",
            "Epoch 28, loss: 0.061275503830984235\n",
            "Epoch 28, loss: 0.06356701022014022\n",
            "Epoch 28, loss: 0.0698355482891202\n",
            "Epoch 28, loss: 0.0711273665074259\n",
            "Epoch 29, loss: 0.007743943948298693\n",
            "Epoch 29, loss: 0.008365006593521684\n",
            "Epoch 29, loss: 0.023595936072524637\n",
            "Epoch 29, loss: 0.02532750047976151\n",
            "Epoch 29, loss: 0.04553946532541886\n",
            "Epoch 29, loss: 0.05180495564127341\n",
            "Epoch 29, loss: 0.06320944760227576\n",
            "Epoch 29, loss: 0.07515530620003119\n",
            "Epoch 30, loss: 0.01211717538535595\n",
            "Epoch 30, loss: 0.014562306459993124\n",
            "Epoch 30, loss: 0.02282392093911767\n",
            "Epoch 30, loss: 0.0324508142657578\n",
            "Epoch 30, loss: 0.035038324538618326\n",
            "Epoch 30, loss: 0.043016497511416674\n",
            "Epoch 30, loss: 0.060403692070394754\n",
            "Epoch 30, loss: 0.06291074003092945\n",
            "Epoch 31, loss: 0.0029069094453006983\n",
            "Epoch 31, loss: 0.005080833565443754\n",
            "Epoch 31, loss: 0.009747954085469246\n",
            "Epoch 31, loss: 0.03236137144267559\n",
            "Epoch 31, loss: 0.04914047196507454\n",
            "Epoch 31, loss: 0.066714221611619\n",
            "Epoch 31, loss: 0.06922355899587274\n",
            "Epoch 31, loss: 0.07002386590465903\n",
            "Epoch 32, loss: 0.00347124133259058\n",
            "Epoch 32, loss: 0.007245359709486365\n",
            "Epoch 32, loss: 0.013207559240981936\n",
            "Epoch 32, loss: 0.015398042276501656\n",
            "Epoch 32, loss: 0.0230547022074461\n",
            "Epoch 32, loss: 0.038178855553269386\n",
            "Epoch 32, loss: 0.05413125269114971\n",
            "Epoch 32, loss: 0.06535631604492664\n",
            "Epoch 33, loss: 0.010815308429300785\n",
            "Epoch 33, loss: 0.012853370513767004\n",
            "Epoch 33, loss: 0.03264276636764407\n",
            "Epoch 33, loss: 0.037029584404081106\n",
            "Epoch 33, loss: 0.03798313363222405\n",
            "Epoch 33, loss: 0.052522408950608224\n",
            "Epoch 33, loss: 0.05881531460909173\n",
            "Epoch 33, loss: 0.07382322679040954\n",
            "Epoch 34, loss: 0.010534572415053844\n",
            "Epoch 34, loss: 0.013801526976749301\n",
            "Epoch 34, loss: 0.02022790419869125\n",
            "Epoch 34, loss: 0.024289204040542245\n",
            "Epoch 34, loss: 0.026480128755792975\n",
            "Epoch 34, loss: 0.037205917527899146\n",
            "Epoch 34, loss: 0.04044827935285866\n",
            "Epoch 34, loss: 0.08402601745910943\n",
            "Epoch 35, loss: 0.008077883161604404\n",
            "Epoch 35, loss: 0.010587579570710659\n",
            "Epoch 35, loss: 0.021121328696608543\n",
            "Epoch 35, loss: 0.0251869298517704\n",
            "Epoch 35, loss: 0.04992866888642311\n",
            "Epoch 35, loss: 0.054108151234686375\n",
            "Epoch 35, loss: 0.06302588898688555\n",
            "Epoch 35, loss: 0.06523032812401652\n",
            "Epoch 36, loss: 0.005285697989165783\n",
            "Epoch 36, loss: 0.005917639820836484\n",
            "Epoch 36, loss: 0.007966698263771832\n",
            "Epoch 36, loss: 0.019593601231463253\n",
            "Epoch 36, loss: 0.02207690302748233\n",
            "Epoch 36, loss: 0.04130625177640468\n",
            "Epoch 36, loss: 0.05563095037359744\n",
            "Epoch 36, loss: 0.05993800994474441\n",
            "Epoch 37, loss: 0.004756427835673094\n",
            "Epoch 37, loss: 0.010474975686520338\n",
            "Epoch 37, loss: 0.011174490151461214\n",
            "Epoch 37, loss: 0.025847626326140016\n",
            "Epoch 37, loss: 0.04749127238756046\n",
            "Epoch 37, loss: 0.0482297443668358\n",
            "Epoch 37, loss: 0.052921741909813136\n",
            "Epoch 37, loss: 0.06319905136479065\n",
            "Epoch 38, loss: 0.014213201589882374\n",
            "Epoch 38, loss: 0.015786752803251147\n",
            "Epoch 38, loss: 0.027382851345464587\n",
            "Epoch 38, loss: 0.04122650693170726\n",
            "Epoch 38, loss: 0.04248381603974849\n",
            "Epoch 38, loss: 0.052709066425450146\n",
            "Epoch 38, loss: 0.05776967585552484\n",
            "Epoch 38, loss: 0.05829204886686057\n",
            "Epoch 39, loss: 0.0022410007659345865\n",
            "Epoch 39, loss: 0.011825739638879895\n",
            "Epoch 39, loss: 0.02691265125758946\n",
            "Epoch 39, loss: 0.028380156960338354\n",
            "Epoch 39, loss: 0.037135911639779806\n",
            "Epoch 39, loss: 0.04950312850996852\n",
            "Epoch 39, loss: 0.0560731403529644\n",
            "Epoch 39, loss: 0.05662481556646526\n",
            "Epoch 40, loss: 0.013172682374715805\n",
            "Epoch 40, loss: 0.017544166650623083\n",
            "Epoch 40, loss: 0.029601728077977896\n",
            "Epoch 40, loss: 0.031991791911423206\n",
            "Epoch 40, loss: 0.04554245714098215\n",
            "Epoch 40, loss: 0.04689282097388059\n",
            "Epoch 40, loss: 0.04883201757911593\n",
            "Epoch 40, loss: 0.06801858136896044\n",
            "Epoch 41, loss: 0.007695208303630352\n",
            "Epoch 41, loss: 0.01522067142650485\n",
            "Epoch 41, loss: 0.017559187952429056\n",
            "Epoch 41, loss: 0.03437474789097905\n",
            "Epoch 41, loss: 0.04885016707703471\n",
            "Epoch 41, loss: 0.04988306306768209\n",
            "Epoch 41, loss: 0.05326406785752624\n",
            "Epoch 41, loss: 0.05772781220730394\n",
            "Epoch 42, loss: 0.007990927435457706\n",
            "Epoch 42, loss: 0.008418704179348424\n",
            "Epoch 42, loss: 0.01267834592727013\n",
            "Epoch 42, loss: 0.034466043376596645\n",
            "Epoch 42, loss: 0.05402683492866345\n",
            "Epoch 42, loss: 0.05485581877292134\n",
            "Epoch 42, loss: 0.05654082601540722\n",
            "Epoch 42, loss: 0.05851994073600508\n",
            "Epoch 43, loss: 0.0034075991716235876\n",
            "Epoch 43, loss: 0.006217621034011245\n",
            "Epoch 43, loss: 0.008236684137955308\n",
            "Epoch 43, loss: 0.02246472821570933\n",
            "Epoch 43, loss: 0.028429182013496757\n",
            "Epoch 43, loss: 0.043194386875256896\n",
            "Epoch 43, loss: 0.04644848918542266\n",
            "Epoch 43, loss: 0.060361971613019705\n",
            "Epoch 44, loss: 0.004625207744538784\n",
            "Epoch 44, loss: 0.008620778564363718\n",
            "Epoch 44, loss: 0.01269098138436675\n",
            "Epoch 44, loss: 0.03324728226289153\n",
            "Epoch 44, loss: 0.04429149394854903\n",
            "Epoch 44, loss: 0.0499014463275671\n",
            "Epoch 44, loss: 0.05309636890888214\n",
            "Epoch 44, loss: 0.05586507613770664\n",
            "Epoch 45, loss: 0.005030239466577768\n",
            "Epoch 45, loss: 0.01932057412341237\n",
            "Epoch 45, loss: 0.020206296467222273\n",
            "Epoch 45, loss: 0.034088437096215785\n",
            "Epoch 45, loss: 0.03880654100794345\n",
            "Epoch 45, loss: 0.04918156948406249\n",
            "Epoch 45, loss: 0.05385629471857101\n",
            "Epoch 45, loss: 0.05398303877154831\n",
            "Epoch 46, loss: 0.0025972879957407713\n",
            "Epoch 46, loss: 0.011800644686445594\n",
            "Epoch 46, loss: 0.022947912802919745\n",
            "Epoch 46, loss: 0.03789137094281614\n",
            "Epoch 46, loss: 0.04512605653144419\n",
            "Epoch 46, loss: 0.04624506377149373\n",
            "Epoch 46, loss: 0.0485181090189144\n",
            "Epoch 46, loss: 0.05924017808865756\n",
            "Epoch 47, loss: 0.005874284543097019\n",
            "Epoch 47, loss: 0.01519837137311697\n",
            "Epoch 47, loss: 0.018581137526780367\n",
            "Epoch 47, loss: 0.03314568428322673\n",
            "Epoch 47, loss: 0.04829793842509389\n",
            "Epoch 47, loss: 0.051353553077206016\n",
            "Epoch 47, loss: 0.0530484908958897\n",
            "Epoch 47, loss: 0.05671490600798279\n",
            "Epoch 48, loss: 0.006682480685412884\n",
            "Epoch 48, loss: 0.025638234801590443\n",
            "Epoch 48, loss: 0.030030283145606518\n",
            "Epoch 48, loss: 0.03351791622117162\n",
            "Epoch 48, loss: 0.034745769342407584\n",
            "Epoch 48, loss: 0.036339810118079185\n",
            "Epoch 48, loss: 0.04367080004885793\n",
            "Epoch 48, loss: 0.06464131223037839\n",
            "Epoch 49, loss: 0.006239220034331083\n",
            "Epoch 49, loss: 0.013056919910013676\n",
            "Epoch 49, loss: 0.014231853769160807\n",
            "Epoch 49, loss: 0.02348004432860762\n",
            "Epoch 49, loss: 0.03301751671824604\n",
            "Epoch 49, loss: 0.052725086570717394\n",
            "Epoch 49, loss: 0.05477441765833646\n",
            "Epoch 49, loss: 0.05537320929579437\n",
            "Epoch 50, loss: 0.001532294787466526\n",
            "Epoch 50, loss: 0.002452765649650246\n",
            "Epoch 50, loss: 0.021181182062719017\n",
            "Epoch 50, loss: 0.025373860786203295\n",
            "Epoch 50, loss: 0.046823698619846255\n",
            "Epoch 50, loss: 0.049491586920339614\n",
            "Epoch 50, loss: 0.05173517676303163\n",
            "Epoch 50, loss: 0.0633932268829085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69Itr4oltOTx",
        "outputId": "3f0dde7b-8883-4e84-df8b-fe3e9815d00e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "random_samples = torch.FloatTensor(np.random.rand(5, 4))\n",
        "\n",
        "random_samples_standardized = torch.FloatTensor(scaler.transform(random_samples))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  predictions = model(random_samples_standardized)\n",
        "  _, predicted_classes = torch.max(predictions, 1)\n",
        "\n",
        "print(\"Random Samples (Standardized):\")\n",
        "print(random_samples_standardized)\n",
        "print(\"Predicted Classes:\")\n",
        "print(predicted_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-SGZMLc9HRo",
        "outputId": "abea4bbf-166a-47c8-ef7d-45c295a7613e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Samples (Standardized):\n",
            "tensor([[-6.7248, -6.5508, -1.5820, -0.9180],\n",
            "        [-6.8447, -4.6840, -1.6838, -0.8634],\n",
            "        [-6.9513, -5.8968, -1.9581, -1.4037],\n",
            "        [-6.8328, -5.2141, -1.7056, -1.3768],\n",
            "        [-6.9149, -5.4712, -1.6365, -1.5281]])\n",
            "Predicted Classes:\n",
            "tensor([0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    }
  ]
}